# Rag-Based-Chatbot-Assistant-for-University
 Students struggle to find admission details (deadlines, eligibility) quickly.  So i made a solution,  A chatbot that answers questions 24/7 using official university documents
# PDF + Web RAG Chatbot with Flask, LangChain, FAISS, and React Frontend

This project is a **Retrieval-Augmented Generation (RAG) chatbot** powered by **Flask**, **LangChain**, **OpenAI GPT models**, and **FAISS**.  
It processes data from **PDF documents** and **web pages** to answer user queries with **context awareness** and **chat history**.  
A **React-based frontend** is provided for an interactive user experience.

---

## ğŸš€ Features

- ğŸ“„ Load and process **PDF files**.
- ğŸŒ Scrape and process **web pages**.
- ğŸ” Store embeddings in **FAISS vector database** for fast retrieval.
- ğŸ§  Maintain **chat history** with `ConversationBufferMemory`.
- ğŸ’¬ Serve a **REST API** using Flask (`/chat` endpoint).
- âš¡ Uses **OpenAI GPT-4o-mini** for responses.
- ğŸ–¥ Interactive **React frontend** with real-time chat.
- ğŸ” Automatically rebuilds FAISS index if not found locally.

---

## ğŸ“‚ Project Structure

```
project/
â”‚-- backend/
â”‚   â”‚-- app.py               # Main Flask app with LangChain integration
â”‚   â”‚-- .env                  # Store your OpenAI API key
â”‚   â”‚-- faiss_index/          # FAISS vector store directory (auto-created)
â”‚   â”‚-- data/
â”‚   â”‚   â””â”€â”€ data.pdf          # PDF file to be processed
â”‚
â”‚-- frontend/
â”‚   â”‚-- package.json          # React dependencies
â”‚   â”‚-- src/                  # React components and pages
â”‚   â”‚-- public/               # Static files
```

---

## ğŸ“¦ Backend Installation (Flask API)

1. **Navigate to backend folder**
```bash
cd backend
```

2. **Create and activate virtual environment**
```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Create `.env` file**
```env
OPENAI_API_KEY=your_openai_api_key_here
```

5. **Run Flask API**
```bash
python app.py
```
Backend will be available at:
```
http://localhost:5000
```

---

## ğŸ’» Frontend Installation (React UI)

1. **Navigate to frontend folder**
```bash
cd frontend
```

2. **Install dependencies**
```bash
npm install
```

3. **Start development server**
```bash
npm run dev
```
Frontend will be available at:
```
http://localhost:3000
```

4. **Build for production**
```bash
npm run build
```

---

## ğŸ“¡ API Usage

### **POST** `/chat`

**Request Body:**
```json
{
  "session_id": "user1",
  "query": "What is mentioned in the vice chancellor's message?"
}
```

**Response Example:**
```json
{
  "answer": "The vice chancellor emphasizes academic excellence...",
  "sources": [
    "D:/Projects/data/data.pdf",
    "https://www.iub.edu.pk/vice-chancellor-message"
  ]
}
```

---

## ğŸ›  Backend Dependencies

Add this to your `requirements.txt`:

```
flask
python-dotenv
langchain
faiss-cpu
openai
```

---

## ğŸ§  How It Works

1. **Data Loading**  
   - PDFs via `PyPDFLoader`
   - Web pages via `WebBaseLoader`

2. **Text Splitting**  
   - `RecursiveCharacterTextSplitter` (`chunk_size=1000`, `chunk_overlap=200`)

3. **Embeddings & Storage**  
   - `OpenAIEmbeddings` for vectorization
   - FAISS for fast retrieval

4. **Query Handling**  
   - Retrieve relevant chunks
   - Generate answers using `ChatOpenAI`
   - Maintain chat history with `ConversationBufferMemory`

5. **Frontend Communication**  
   - React frontend sends queries to Flask API
   - Displays responses and sources in real-time

---

## ğŸ“Œ Notes

- First run will build FAISS index; subsequent runs will load it.
- Replace example URLs and PDF with your own data.
- For production, consider deploying Flask API and React frontend separately.

---

## ğŸ“œ License

This project is for educational and development purposes.  
Feel free to modify and use in your own projects.
